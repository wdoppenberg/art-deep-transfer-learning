{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From one art to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_modes=(\"fine_tuning\" \"off_the_shelf\")\n",
    "dataset_name = \"test\" #The name of your dataset\n",
    "\n",
    "metadata_path=\"metadata\" #The path to your metadata file in .csv extension\n",
    "jpg_images_path=\"figures\" #The path to your images in *.jpg\n",
    "\n",
    "results_path=\"results\" #The path where wou would like to store your results\n",
    "datasets_path=\"datasets\" #The path where the hdf5 files will be stored for the experiments\n",
    "\n",
    "tl_mode=\"fine_tuning\" #Choose a pre-training mode from tl_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"transfer_learning_experiment/from_one_art_to_another/transfer_learning_experiment.py\", line 189, in <module>\n",
      "    experiment.start_experiment()\n",
      "  File \"transfer_learning_experiment/from_one_art_to_another/transfer_learning_experiment.py\", line 151, in start_experiment\n",
      "    metadata = self.get_metadata()\n",
      "  File \"transfer_learning_experiment/from_one_art_to_another/transfer_learning_experiment.py\", line 44, in get_metadata\n",
      "    return(pd.read_csv(self.metadata_path))\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 676, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 448, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 880, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1114, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1891, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 529, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 719, in pandas._libs.parsers.TextReader._get_header\n",
      "  File \"pandas/_libs/parsers.pyx\", line 915, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 2070, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n"
     ]
    }
   ],
   "source": [
    "!python transfer_learning_experiment/from_one_art_to_another/transfer_learning_experiment.py --dataset_name $dataset_name --ANN \"RijksVGG19\" --metadata_path $metadata_path --jpg_images_path $jpg_images_path --results_path $results_path --datasets_path $datasets_path --tl_mode $tl_mode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet to art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"transfer_learning_experiment/imagenet_to_art/transfer_learning_experiment.py\", line 189, in <module>\n",
      "    experiment.start_experiment()\n",
      "  File \"transfer_learning_experiment/imagenet_to_art/transfer_learning_experiment.py\", line 151, in start_experiment\n",
      "    metadata = self.get_metadata()\n",
      "  File \"transfer_learning_experiment/imagenet_to_art/transfer_learning_experiment.py\", line 44, in get_metadata\n",
      "    return(pd.read_csv(self.metadata_path))\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 676, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 448, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 880, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1114, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/Users/doppenberg/Documents/Deep Learning/cs4240-project/env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1891, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 374, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 673, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File None does not exist: 'None'\n"
     ]
    }
   ],
   "source": [
    "!python transfer_learning_experiment/imagenet_to_art/transfer_learning_experiment.py --dataset_name $dataset_name --ANN \"RijksVGG19\" --metadata_path $metadata_path --jpg_images_path $jpg_images_path --results_path $results_path --datasets_path $datasets_path --tl_mode $tl_mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
