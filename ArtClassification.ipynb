{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArtClassification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wdoppenberg/art-deep-transfer-learning/blob/master/ArtClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNj8i9w2yVMc",
        "colab_type": "text"
      },
      "source": [
        "# Deep Transfer Learning for Art Classification Problems - A Reproducibility Study\n",
        "\n",
        "By [Jasper Veen](https://www.linkedin.com/in/jasper-veen), [Bruno Martens](https://www.linkedin.com/in/brunomartens), [Max Hermans](https://www.linkedin.com/in/max-hermans-8324b0b1), and [Wouter Doppenberg](https://www.linkedin.com/in/wouterdoppenberg)\n",
        "\n",
        "Delft University of Technology, the Netherlands\n",
        "\n",
        "[Repository](https://github.com/wdoppenberg/art-deep-transfer-learning)\n",
        "\n",
        "<br></br>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Original Paper by: Matthia Sabatelli, Mike Kestemont, Walter Daelemans, and Pierre Geurts\n",
        "\n",
        "Université de Liège, Belgium\n",
        "\n",
        "Universiteit Antwerpen, Belgium\n",
        "\n",
        "[Original study's repository](https://github.com/paintception/Deep-Transfer-Learning-for-Art-Classification-Problems)\n",
        "\n",
        "[Original paper](https://www.researchgate.net/publication/327498843_Deep_Transfer_Learning_for_Art_Classification_Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYfc-N2X1Ywg",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjq5b-RrnVCO",
        "colab_type": "text"
      },
      "source": [
        "[DOWNLOAD DATASET](https://drive.google.com/open?id=1-nOa-93oohjw2mm6taBb1Y4TpXIDgSID) (Google Drive)\n",
        "\n",
        "[DOWNLOAD DATASET](https://www.kaggle.com/brunomartens/cs4240dl-rp) (Kaggle)\n",
        "\n",
        "Otherwise, create your own splits using the data from [this](https://figshare.com/articles/Rijksmuseum_Challenge_2014/5660617) link; download `rijksimg.tar` and putting the images in a folder called `images`. After this clone the [GitHub repository](https://github.com/wdoppenberg/art-deep-transfer-learning), install the dependencies and run `create_splits.py`.\n",
        "\n",
        "Add these to your Google Drive in order to work with them through Colab. Make sure that you change directory accordingly. \n",
        "\n",
        "Make sure you activate the GPU runtime under `Runtime` > `Change runtime type`. If you happen to have a CUDA-enabled GPU locally, it might be more worthwhile to download the dataset and run this notebook locally.\n",
        "\n",
        "Adjust the variables to adjust the notebook to the desired experiment type, and make sure to *run* the following cell before continuing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xA1RicfdLjv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown Path of workspace folder relative from Google Drive root you wish to execute this notebook from, also serves as root folder for `CHECKPOINT_ROOT` and `DATASETS_PATH`.\n",
        "WORKSPACE_PATH = 'Colab Notebooks/cs4240-project' #@param {type:'string'}\n",
        "#@markdown Define whether to use pretrained weights (ImageNet).\n",
        "PRETRAINED_ON_IMAGENET = False #@param ['True', 'False'] {type:'raw'}\n",
        "#@markdown Base path to store the model checkpoint files.\n",
        "CHECKPOINT_ROOT = 'models/PyTorch/' #@param {type:'string'}\n",
        "#@markdown Base path pointing to the dataset files. Expecting HDF5 files, split into `training.hdf5`, `validation.hdf5`, and `testing.hdf5` or similar.\n",
        "DATASETS_PATH = 'datasets/Jap/' #@param {type:'string'}\n",
        "#@markdown Model type name.\n",
        "MODEL = 'EfficientNet' #@param ['VGG19', 'ResNet50', 'EfficientNet'] {type:'string'}\n",
        "#@markdown The challenge to attempt. All challenges as described in the paper have been implemented, which refer to type and creator classification, respectively.\n",
        "CHALLENGE = 'material' #@param ['material', 'type', 'creator'] {type:'string'}\n",
        "#@markdown How many epochs to train for.\n",
        "EPOCHS_PER_SESSION = 5 #@param {type: \"slider\", min: 1, max: 20}\n",
        "\n",
        "WORKSPACE_PATH = '/content/drive/My Drive/'+WORKSPACE_PATH\n",
        "\n",
        "CHECKPOINT_PATH = CHECKPOINT_ROOT + CHALLENGE + '/'\n",
        "training_type = 'FineTuning' if PRETRAINED_ON_IMAGENET else 'OffTheShelf'\n",
        "EXPERIMENT_NAME = f'{MODEL}_{training_type}_Rijks_{CHALLENGE}'\n",
        "print(\n",
        "    f'Running experiment with the following name: {EXPERIMENT_NAME}\\n'\n",
        "    f'Using training.hdf5, validation.hdf5, and testing.hdf5 from {DATASETS_PATH}\\n'\n",
        "    f'Saving checkpoint files under {CHECKPOINT_PATH}\\n'\n",
        "    f'Training for {EPOCHS_PER_SESSION} epochs'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLA2jBwhGyNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNLwOPiYEIbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd $WORKSPACE_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yl6H2l2_iUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -q -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exdq-7gwtrs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import io\n",
        "from pathlib import Path\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OCQe2ip1gRJ",
        "colab_type": "text"
      },
      "source": [
        "## Create DataLoaders\n",
        "\n",
        "In order to train or evaluate the networks, `DataLoader` instances needed to be custom-made for the acquired dataset. This meant first creating a custom `HDF5Dataset` with `Dataset` as a base class. This allowed for easy minibatch generation in a training or evaluation loop. \n",
        "\n",
        "The necessary transformations on the data are implemented at this phase too, resizing and normalizing the images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGQKaMG1GiLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test dataset\n",
        "i = 1234\n",
        "with h5py.File(DATASETS_PATH+'training.hdf5', 'r') as f:\n",
        "    print(f['fullname_creator'][i], f['material'][i], f['type'][i])\n",
        "    img = Image.open(\n",
        "        io.BytesIO(f['images'][i])\n",
        "        ).convert('RGB')\n",
        "img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1jIadHv5T8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = DATASETS_PATH+'training.hdf5'\n",
        "test_path = DATASETS_PATH+'testing.hdf5'\n",
        "val_path = DATASETS_PATH+'validation.hdf5'\n",
        "\n",
        "input_size = 224\n",
        "batch_size = 32 if MODEL!='EfficientNet' else 16\n",
        "\n",
        "labels = {\n",
        "    'material':'material_cat',\n",
        "    'type':'type_cat',\n",
        "    'creator':'fullname_creator_cat'\n",
        "}\n",
        "\n",
        "classes = {\n",
        "    'material':128,\n",
        "    'type':534,\n",
        "    'creator':6620\n",
        "}\n",
        "\n",
        "num_classes = classes[CHALLENGE]\n",
        "\n",
        "norm_mean = (0.485, 0.456, 0.406)\n",
        "norm_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(norm_mean, norm_std)\n",
        "])\n",
        "\n",
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "            # The normalize code -> t.sub_(m).div_(s)\n",
        "        return tensor\n",
        "\n",
        "unnormalize = UnNormalize(norm_mean, norm_std)\n",
        "\n",
        "TensorToImage = transforms.ToPILImage(mode='RGB')\n",
        "\n",
        "class HDF5Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, challenge):\n",
        "        self.f = h5py.File(path, 'r')\n",
        "\n",
        "        self.n_images = len(self.f['images'])\n",
        "        self.challenge = challenge\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        return (\n",
        "            transform(\n",
        "                Image.open(\n",
        "                    io.BytesIO(self.f['images'][idx])\n",
        "                ).convert('RGB')\n",
        "            ),\n",
        "            int(self.f[self.challenge][idx])\n",
        "        )\n",
        "    \n",
        "    def random(self):\n",
        "        return self.__getitem__(\n",
        "            random.randint(0, self.n_images)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_images\n",
        "\n",
        "    def __del__(self):\n",
        "        self.f.close()\n",
        "\n",
        "train_dataset = HDF5Dataset(train_path, labels[CHALLENGE])\n",
        "test_dataset = HDF5Dataset(test_path, labels[CHALLENGE])\n",
        "validation_dataset = HDF5Dataset(val_path, labels[CHALLENGE])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                        batch_size=batch_size, \n",
        "                                        shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                        batch_size=1, \n",
        "                                        shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset,\n",
        "                                        batch_size=batch_size, \n",
        "                                        shuffle=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2uhdLrg1lca",
        "colab_type": "text"
      },
      "source": [
        "## Create or load model\n",
        "\n",
        "The following cell creates or loads the PyTorch model state dependent on the experiment setup. If a checkpoint file associated with the `EXPERIMENT_NAME` exists, it will automatically load that file for further use. \n",
        "\n",
        "Besides loading model state, this cell also loads the optimizer state, as well as the average loss per epoch of previous training sessions.\n",
        "\n",
        "`nn.CrossEntropyLoss()` is used as a loss function, just as the original project. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVglX9sF4z-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(name, pretrained, nc):\n",
        "    print(f'Model: {name}, Pretrained: {pretrained}, num_classes: {nc}')\n",
        "    if name == 'VGG19':\n",
        "        model = models.vgg19(pretrained=pretrained)\n",
        "        model.classifier[6] = nn.Linear(4096, nc)\n",
        "        return model\n",
        "\n",
        "    elif name == 'ResNet50':\n",
        "        model = models.resnet50(pretrained=pretrained)\n",
        "        model.fc = nn.Linear(2048, nc)\n",
        "        return model\n",
        "\n",
        "    elif name == 'EfficientNet':\n",
        "        if pretrained:\n",
        "            model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "        else:\n",
        "            model = EfficientNet.from_name('efficientnet-b7')\n",
        "        model._fc = nn.Linear(2560, nc)\n",
        "        return model\n",
        "    else:\n",
        "        print(f'Model called {name} not found...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HRzoIfOjXJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path_full = CHECKPOINT_PATH+EXPERIMENT_NAME+'.pth'\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "learning_rate = 1e-3\n",
        "momentum = 0.9\n",
        "\n",
        "if Path(checkpoint_path_full).is_file():\n",
        "    print('Using checkpoint file...')\n",
        "    if ~torch.cuda.is_available():\n",
        "        checkpoint = torch.load(checkpoint_path_full, map_location=torch.device('cpu'))\n",
        "    else:    \n",
        "        checkpoint = torch.load(checkpoint_path_full)\n",
        "\n",
        "    model = get_model(MODEL, False, num_classes)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Activate the GPU in the Colab runtime settings to utilize cuda acceleration\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "        loss_function.cuda()\n",
        "        print(f'Using GPU: {torch.cuda.get_device_name(0)}')\n",
        "    else:\n",
        "        print('Using CPU')\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "\n",
        "    avg_train_losses = checkpoint['avg_train_losses']\n",
        "    avg_val_losses = checkpoint['avg_val_losses']\n",
        "    accuracy = checkpoint['accuracy']\n",
        "\n",
        "else:\n",
        "    print(f'No checkpoint file named {EXPERIMENT_NAME}.pth found; Creating new model...')\n",
        "    model = get_model(MODEL, PRETRAINED_ON_IMAGENET, num_classes)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "        loss_function.cuda()\n",
        "        print(f'Using GPU: {torch.cuda.get_device_name(0)}')\n",
        "    else:\n",
        "        print('Using CPU')\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "    epoch = 0\n",
        "    avg_train_losses, avg_val_losses = [], []\n",
        "    accuracy = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzbC417W10q3",
        "colab_type": "text"
      },
      "source": [
        "## Train model\n",
        "\n",
        "Executing the following cell will train the model using an editable checkpoint strategy (to prevent one from losing all training progress). \n",
        "\n",
        "Be aware that if the previous cell did not state that a *GPU* will be used, it is a very slow process, and will probably not be realistic to train to any satisfactory degree. \n",
        "\n",
        "The loss values are recorded in the checkpoint files, however be aware that these are the average loss values per epoch. This means that especially in the first few epochs the training loss may appear higher, but this is caused by the fact that the validation error is determined at the end of a training epoch, meaning on average the loss would be lower if the loss gradient is still relatively steep. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhHiS3ReFtMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_list = range(epoch+1, epoch + (EPOCHS_PER_SESSION) + 1)\n",
        "\n",
        "for e in epoch_list:\n",
        "    print(f'\\n-----Epoch {e} started.-----\\n')\n",
        "\n",
        "    since = time.time()\n",
        "    \n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    model.train()\n",
        "    for batch, (images, labels) in enumerate(train_loader, 1):\n",
        "        if torch.cuda.is_available():\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "\n",
        "        loss = loss_function(logits, labels)\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 200 == 0 or batch == 1 or batch==len(train_loader):\n",
        "            time_elapsed = time.time() - since\n",
        "            print(\n",
        "                f'Training loss = {np.average(train_losses):8.3f} | ',\n",
        "                f'Batch # {batch:6.0f} | [{time_elapsed//60:3.0f}m {time_elapsed%60:2.0f}s]')\n",
        "        \n",
        "    model.eval()\n",
        "    score = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "            logits = model(images)\n",
        "            val_losses.append(loss_function(logits, labels).item())\n",
        "\n",
        "            top_p, top_class = logits.topk(1, dim=1)\n",
        "            correct = top_class.squeeze() == labels\n",
        "            score += torch.sum(correct.float())\n",
        "\n",
        "    # Save epoch stats\n",
        "    avg_train_losses.append(np.average(train_losses))\n",
        "    avg_val_losses.append(np.average(val_losses))\n",
        "    accuracy.append(score/len(validation_dataset))\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(\n",
        "        f\"\\nSummary:\\n\",\n",
        "        f\"\\tEpoch: {e}/{epoch_list[-1]}\\n\",\n",
        "        f\"\\tLearning Rate: {learning_rate}\\n\",\n",
        "        f\"\\tTraining Loss: {avg_train_losses[-1]:.5f}\\n\",\n",
        "        f\"\\tValidation Loss: {avg_val_losses[-1]:.5f}\\n\",\n",
        "        f\"\\tAccuracy: {accuracy[-1]*100:.2f}%\\n\",\n",
        "        f\"\\tDuration: {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s\"\n",
        "    )\n",
        "    \n",
        "    print(f'-----Epoch {e} finished.-----\\n')\n",
        "\n",
        "    print(f'Saving model as {checkpoint_path_full} at epoch #{e}')\n",
        "    torch.save(\n",
        "        {\n",
        "            'epoch': e,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'avg_train_losses': avg_train_losses,\n",
        "            'avg_val_losses': avg_val_losses,\n",
        "            'accuracy': accuracy\n",
        "        }, \n",
        "        checkpoint_path_full\n",
        "    )\n",
        "\n",
        "# Ensuring multiple runs of this cell stack up\n",
        "epoch = e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv79HwER15VR",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate model with test data\n",
        "\n",
        "The following cell calculates the accuracy over the testing dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p05rr8oCICLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test accuracy\n",
        "\n",
        "score = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "        logits = model(images)\n",
        "\n",
        "        top_p, top_class = logits.topk(1, dim=1)\n",
        "        correct = top_class.squeeze() == labels\n",
        "        score += torch.sum(correct.float())\n",
        "\n",
        "test_accuracy = score/len(test_dataset)\n",
        "\n",
        "print(\n",
        "    f\"Test summary:\\n\",\n",
        "    f\"\\tEpochs: {e}\\n\",\n",
        "    f\"\\tScore: {score:.0f}/{len(test_dataset)} correct inferences\\n\",\n",
        "    f\"\\tTesting accuracy: {test_accuracy*100:.2f}%\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNR4sJJG2FQe",
        "colab_type": "text"
      },
      "source": [
        "## Plot training vs. validation loss\n",
        "\n",
        "This cell plots the training and validation loss over the epochs. Once again, these are average loss values over epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kg1TkbvnJPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(avg_train_losses)+1), avg_train_losses, label='Training Loss')\n",
        "plt.plot(range(1,len(avg_train_losses)+1), avg_val_losses, label='Validation Loss')\n",
        "\n",
        "#find position of lowest validation loss\n",
        "minposs = avg_val_losses.index(min(avg_val_losses))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 10) # consistent scale\n",
        "plt.xlim(0, len(avg_train_losses)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWTG96ph2OMC",
        "colab_type": "text"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCAj4DkOYft9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "metadata = pd.read_csv(DATASETS_PATH+'metadata_rijks_enc.csv')\n",
        "\n",
        "df_material = metadata[['material', 'material_cat']].copy()\n",
        "df_material.drop_duplicates(inplace=True)\n",
        "df_material.columns = ['string', 'label']\n",
        "\n",
        "df_type = metadata[['type', 'type_cat']].copy()\n",
        "df_type.drop_duplicates(inplace=True)\n",
        "df_type.columns = ['string', 'label']\n",
        "\n",
        "df_creator = metadata[['fullname_creator', 'fullname_creator_cat']].copy()\n",
        "df_creator.drop_duplicates(inplace=True)\n",
        "df_creator.columns = ['string', 'label']\n",
        "\n",
        "dict_labels = dict(material=df_material, type=df_type, creator=df_creator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci81DEDWeApB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, label = next(iter(test_loader))\n",
        "if torch.cuda.is_available():\n",
        "    image, label = image.cuda(), label.cuda()\n",
        "model.eval()\n",
        "\n",
        "logits = model(image)\n",
        "ground_truth = label.item()\n",
        "prediction = logits.argmax(dim=1).item() \n",
        "\n",
        "df = dict_labels[CHALLENGE]\n",
        "gt_string = df[df['label']==ground_truth]['string'].item()\n",
        "pred_string = df[df['label']==prediction]['string'].item()\n",
        "corr = 'Correct!' if prediction==ground_truth else 'Incorrect.'\n",
        "print(\n",
        "    f'Ground truth: [{ground_truth}] {gt_string}\\n'\n",
        "    f'Prediction: [{prediction}] {pred_string}\\n'+\n",
        "    corr\n",
        ")\n",
        "TensorToImage(unnormalize(image[0].cpu()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPixp6NOYPdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saliency maps\n",
        "image, label = next(iter(test_loader))\n",
        "if torch.cuda.is_available():\n",
        "    image, label = image.cuda(), label.cuda()\n",
        "model.eval()\n",
        "\n",
        "image.requires_grad_()\n",
        "\n",
        "logits = model(image)\n",
        "print(logits.argmax(dim=1))\n",
        "\n",
        "score_max_index = logits.argmax(dim=1)\n",
        "score_max = logits[0, score_max_index]\n",
        "\n",
        "score_max.backward()\n",
        "\n",
        "saliency, _ = torch.max(image.grad.data.abs(), dim=1)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "ax.imshow(saliency[0])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpOR8xupSa7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}